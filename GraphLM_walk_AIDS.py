# -*- coding: utf-8 -*-
"""GraphLM_walk_AIDS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MOA8mc8b__Fb1Nk8yu3iMNdm_vUhL2Hi
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/dtylor/WalkRNN.git
# %cd WalkRNN
!ls

!curl https://course-v3.fast.ai/setup/colab | bash

import fastai
import pandas as pd

from fastai.utils.show_install import *
show_install()

str(fastai.__dict__['version'])
!more /usr/local/lib/python3.6/dist-packages/fastai/version.py

!ls

from google.colab import drive

drive.mount("/content/drive")

from utilities import load_graph_kernel_graph, load_graph_kernel_labels

node_mappings = [{
        0:       "C",
        1:       "O",
        2:       "N",
        3:       "Cl",
        4:       "F",
        5:       "S",
        6:       "Se",
        7:       "P",
        8:       "Na",
        9:       "I",
        10:      "Co",
        11:      "Br",
        12:      "Li",
        13:      "Si",
        14:      "Mg",
        15:      "Cu",
        16:      "As",
        17:      "B",
        18:      "Pt",
        19:      "Ru",
        20:      "K",
        21:      "Pd",
        22:      "Au",
        23:      "Te",
        24:      "W",
        25:      "Rh",
        26:      "Zn",
        27:      "Bi",
        28:      "Pb",
        29:      "Ge",
        30:      "Sb",
        31:      "Sn",
        32:      "Ga",
        33:      "Hg",
        34:      "Ho",
        35:      "Tl",
        36:      "Ni",
        37:      "Tb"
}]

label_maps={"node_labels": node_mappings}

G = load_graph_kernel_graph("./AIDS", mappings=label_maps)
y = load_graph_kernel_labels("./AIDS")

from module import get_structural_signatures, walk_as_string

newGraph, pca, kmeans = get_structural_signatures(G)

walks = walk_as_string(newGraph, componentLabels = y)

from fastai.text import *
from sklearn.model_selection import train_test_split
import numpy

walks.head()

walks.shape

from sklearn.model_selection import train_test_split
import numpy
data = list(set(walks.component))
x_traina ,x_test = train_test_split(data,test_size=0.1)    
x_train ,x_val = train_test_split(x_traina,test_size=0.2)

train_tmp = pd.DataFrame(x_train)
train_tmp.columns = ['component']
df_train = pd.merge(walks, train_tmp, on='component', sort=False)
df_train.shape

test_tmp = pd.DataFrame(x_test)
test_tmp.columns = ['component']
df_test = pd.merge(walks, test_tmp, on='component', sort=False)
df_test.shape

val_tmp = pd.DataFrame(x_val)
val_tmp.columns = ['component']
df_val = pd.merge(walks, val_tmp, on='component', sort=False)
df_val.shape

!mkdir result
mypath = './result'

data_lm = TextLMDataBunch.from_df(train_df=df_train[['walk', 'label']], valid_df=df_val[[
                                  'walk', 'label']],  path=mypath, text_cols='walk', label_cols='label')

data_lm.save('data_lm.pkl')

!ls -l ./result

bs = 32
# load the data (can be used in the future as well to prevent reprocessing)
data_lm = load_data(mypath, 'data_lm.pkl', bs=bs)

data_lm.show_batch() # take a look at the batch fed into the GPU

#awd_lstm_lm_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.25,
      #                    hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)

#awd_lstm_clas_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.4,
       #                hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5, tie_weights=True, out_bias=True)


#awd_lstm_lm_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.25,hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)

#awd_lstm_clas_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)
#awd_lstm_lm_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.25,
 #                         hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)

#awd_lstm_clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.4,
  #                     hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)

#dAWD_LSTM = {'hid_name':'emb_sz', 'url':URLs.WT103_FWD, 'url_bwd':URLs.WT103_BWD,'config_lm':awd_lstm_lm_config, 'split_lm': awd_lstm_lm_split, 'config_clas':awd_lstm_clas_config, 'split_clas': awd_lstm_clas_split}

#awd_lstm_lm_config = dict(emb_sz=400, n_hid=1152, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.1, hidden_p=0.15, input_p=0.25, embed_p=0.02, weight_p=0.2, tie_weights=True, out_bias=True)

awd_lstm_lm_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.1, hidden_p=0.15, input_p=0.25, embed_p=0.02, weight_p=0.2, tie_weights=True, out_bias=True)
awd_lstm_clas_config = dict(emb_sz=400, n_hid=400, n_layers=1, pad_token=1, qrnn=False, bidir=False, output_p=0.4,  hidden_p=0.3, input_p=0.4, embed_p=0.05, weight_p=0.5)

#torch.cuda.set_device(1)

learn = language_model_learner(data_lm,arch=AWD_LSTM,config= awd_lstm_lm_config,drop_mult=1.8, callback_fns=ShowGraph,pretrained=False)
learn.lr_find()
learn.recorder.plot()
learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))
learn.recorder.plot_losses()
learn.save('fit-head')

# !mkdir /content/drive/My\ Drive/AIDS
# !cp -r /content/result /content/drive/My\ Drive/AIDS

#learn.load('fit-head')
learn.unfreeze()
learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(3, .05, moms=(0.8,0.7))

learn.save('fit-head')

!cp -r /content/result /content/drive/My\ Drive/AIDS

learn.save_encoder('fine_tuned_enc3')

df = walks.sample(frac=1).reset_index(drop=True)
df['index1']=df.index
#g = df.groupby('node')
g = df.groupby('component')
df['RN'] = g['index1'].rank(method='min')
#df[(df['RN']==1.0) & (df['component']=='1')].head()
df[df['component']==1].head()
#df.head()

"""Choose a path per node and concatenate for entire component"""

df.groupby('component')['walk'].apply(lambda x: ', '.join(x))

def f(x):
     return Series(dict(label = x['label'].min(), text =  ', '.join(x['walk'])))
df_text_comp = df[(df['RN']<=6.0)].groupby('component').apply(f)
df_text_comp.head()

df_text_comp['component']= df_text_comp.index
df_text_comp.index.names = ['comp']
df_text_comp.head()

train = pd.merge(df_text_comp, train_tmp, on='component', sort=False)
test =  pd.merge(df_text_comp, test_tmp, on='component', sort=False)
val =  pd.merge(df_text_comp, val_tmp, on='component', sort=False)
(train.shape,val.shape, test.shape, train.shape[0]/df_text_comp.shape[0])

bs=32#48

data_clas = TextClasDataBunch.from_df(train_df=train[['text','label']],valid_df=val[['text','label']],  path=mypath, text_cols='text',label_cols = 'label', vocab=data_lm.vocab)

data_clas.save('tmp_clas')

data_clas = load_data(mypath, 'tmp_clas', bs=bs)

data_clas.show_batch()

learn = text_classifier_learner(data_clas,arch=AWD_LSTM,config = awd_lstm_clas_config, drop_mult=1.7,pretrained=False)
learn.load_encoder('fine_tuned_enc3')
learn.freeze()

gc.collect();

learn.lr_find()

learn.recorder.plot()

learn.fit_one_cycle(1, 5e-02, moms=(0.8,0.7))

def predict(test,learn):
  predictions=[]
  for index, row in test.iterrows():
    p=learn.predict(row['text'])
    #print((row['label'],str(p[0])))
    predictions.append((row['text'],str(row['label']),str(p[0])))
  dfpred = pd.DataFrame(predictions)
  dfpred.columns=['text','label','prediction']
  match=dfpred[(dfpred['label']==dfpred['prediction'])]
  #match.head()
  print((dfpred.shape[0], match.shape[0],match.shape[0]/dfpred.shape[0]))

learn.fit_one_cycle(1, 5e-02, moms=(0.8,0.7))

learn.save('first')

learn.load('first');

learn.freeze_to(-2)
learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))

predict(test,learn)

learn.save('second')

learn.load('second');

learn.freeze_to(-3)
learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))

predict(test,learn)

learn.save('third')

learn.load('third');

learn.unfreeze()
learn.fit_one_cycle(4, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))

predict(test,learn)

learn.model
